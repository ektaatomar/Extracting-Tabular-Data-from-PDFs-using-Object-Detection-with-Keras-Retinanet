# Extracting-Tabular-Data-from-PDFs-using-Object-Detection-with-Keras-Retinanet
Inspired by work of https://github.com/fizyr/keras-retinanet.git 

## GPU Requirements
To fulfill the GPU needs, we utilized Google Colab platform as our personal resources were limited in that capacity. Not to mention that Colab GPU allocation have it's own strategies, depending on your past usage your allocation may differ. In our case, we managed to get pretty good model with these resources. 

## Enabling GPU on Colab
https://colab.research.google.com/notebooks/gpu.ipynb

## Datasets
We are aware that finding a quality public dataset for table detection can be a task, so here are few that we used in our training.
https://www.kaggle.com/monuirctc/table-detection  
http://www.tamirhassan.com/html/dataset.html - EU documents link

## Required Files

Images- JPEG is the prefered format, the code to convert PNG into JPEG files also included in the script.

Annotations- XML files. Respective table annotations are included in these datasets. All the tables are annotated under 'table' class name.

We encorage to develop understandiing of the annotation file formats. 

When using your own pdfs and images, annotations can be generated by using:
https://tzutalin.github.io/labelImg/ App 
You can read about the package here:
https://github.com/tzutalin/labelImg Python Package

Train and Test text files- These essentially contain the name of image files(without the extention) to be used for training and testing.

## Preparing CSV Files for Training
After getting all above files ready and in place, next step is to create CSV files with the annotation information by executing build_logos.py script. For obvious reasons, it would generate Train and Test CSV files.

## Training and Test 
Trained the model on our dataset while using the pretrained COCO weights which made the training faster and more precise. After training, converted model into an inference model, ready to do the table object detection. Your model will be saved under output.h5 file format under keras-retinanet folder.
Evaluated its performance with retinanet_test.csv, which turned out to be very impressive. At this stage, mAP is in 90-100% range for the test sample images.

## Putting Model to Work





Collaborators:

Isra Abuhasana 
https://github.com/iHasna 

Ekta Tomar
https://github.com/ektaatomar
